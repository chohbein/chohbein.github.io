<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Cristian Hohbein</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, sans-serif;
      max-width: 800px;
      margin: 40px auto;
      padding: 0 16px;
      line-height: 1.6;
      color: #111;
      background-color: #e6dac1;
    }
    h1 { margin-bottom: 0; }
    h2 { margin-top: 4px; font-weight: normal; color: #444; }
    a { color: #0366d6; text-decoration: none; }
    a:hover { text-decoration: underline; }
  </style>
</head>
<body>
  <h1>Cristian Hohbein</h1>
  <h2>Machine Learning Engineer</h2>

  <p>
    I am an aspiring machine learning engineer based in Southern California. Here are a few of my projects, see their respective repositories for a more in-depth journal.
  </p>

  <h3>Projects</h3>
<section class="project">
  <h4><a href="https://github.com/chohbein/newsapp">News Article Aggregation Website</a></h4>
  <p class="tech">
    Python · SQL · AWS · NLP · webscraping · multi-document summarizing · keyword extraction · database management
  </p>
  <ul style="list-style-type: disc; margin-left: 20px;">
    <li>This passion project of mine is an end-to-end date pipeline to webscrape news articles from various sources, cluster similar articles, extract keywords, and summarize each article cluster into a concise paragraph. </li>
    <li>Scraping was done with Selenium, orchestrated by AWS Lambda + EC2 with a relational AWS RDS database for storage. </li>
    <li>Keyword extraction used a weighted ensemble of Part-of-Speech + Named Entity recognition (spaCy), Semantic-Relevance (KeyBERT), and manually-included common keywords.</li>
    <li>The article clustering process was decided by testing 2 different approaches:  <a href="https://aclanthology.org/W00-0403.pdf">Centroid-Based Summarization of Multiple Documents</a> vs
    <a href="https://arxiv.org/pdf/2110.08499">PRIMERA: Pyramid-based Masked Sentence Pre-Training for Multi-doc Summarizing</a>. Our testing found that PRIMARA gave better summaries; see the <a href="https://github.com/chohbein/newsapp/blob/main/README.md">project repo</a> for more info on my process. </li>
  </ul>
  <video width="640" height="360" controls>
  <source src="news_site_vid.mov" type="video/mp4">
  Your browser does not support the video tag.
</video>
</section>
<hr>
  
<section class="project">
  <h4><a href="https://github.com/chohbein/Cancer-Detection">Histopathologic Cancer Detection</a></h4>
  <p class="tech">CNN · GPU Training · PyTorch · scikit-learn</p>
  <ul style="list-style-type: disc; margin-left: 20px;">
  <li>This is my final project for a deep learning course. I compared 2 different CNN architectures to predict the presence of tumors in histopathologic images.</li>
  <li>One of the major achievements I took from this project was the performance tuning I made to work within the limits of my poor little laptop GPU. </li>
  <li>Initially, I was hit with long overheating and long training times. I resolved this with techniques such as mixed precision, multiple workers, image downsizing, and batch-size tuning.</li>
  <li>I approached model architecture by testing 2 different hypotheses: Because my visual analysis of the images showed no noticable indications of cancerous features, I suspected a model focused on fine-grained details would work best.</li>
  <li>H<sub>0</sub>: focus on fine-grained details
    <ul>
      <li>Small kernels to capture small, refined details</li>
      <li>Minimal pooling to maintain detail.</li>
      <li>Padding to maintain edge information.</li>
      <li>Light dropout to reduce overfitting while also maintaining its capacity to recognize subtle patterns.</li>
    </ul></li>
    <li>H<sub>a</sub>: a focus on broader trends in the images.
      <ul>
        <li>Larger kernels</li>
        <li>Aggressive pooling to emphasize large features.</li>
        <li>High dropout to help broad-feature neurons from learning noise.
      </ul>
    </li>
  </ul>
  <h7>Final improving steps</h7>
  <p class="tech">
    <ul>
      <li>Early stopping</li>
      <li>LR Scheduling</li>
      <li>Image alteration</li>
    </ul>
  </p>
  <b>Results</b>
  <p class="tech">
  Our model focusing on fine details within the images scored better. Thus, we accept our null hypothesis.
  After further improving steps, we concluded with the following:
  <br>
  <br>
  
  ROC-AUC:
  0.9813459611111561
  <br>
  <br>
  Prioritized false-negative rate down to 2%
  </p>
</section>
<hr>

<section class="project">
  <h4><a href="https://github.com/chohbein/GAN">Monet Painting GAN</a></h4>
  <p class="tech">Unpaired Image Style Transfer · PyTorch · CycleGAN · CLIP Embeddings · GANs</p>
  <ul style="list-style-type: disc; margin-left: 20px;">
    <li>Unpaired image style transfer to turn photos into Monet-style paintings.</li>
    <li>Compared two architectural approaches: CycleGAN (baseline) vs. a GAN conditioned on pre-trained CLIP embeddings.</li>
    <li>CycleGAN (baseline)</li>
      <ul>
        <li>Performed unpaired image-to-image translation as a baseline.</li>
        <li>Stabilized and improved training with adjustments including spectral normalization, label smoothing, noise injection, delayed discriminator updates, mixed precision, and learning rate tuning.</li>
      </ul>
    <li>CLIP-Conditioned GAN</li>
      <ul>
        <li>Uses frozen pre-trained CLIP embeddings to provide semantic guidance to the generator.</li>
        <li>U-Net generator skip connections preserve fine-grained spatial detail and structure.</li>
        <li>CLIP-based perceptual loss preserves the original content while applying Monet style.</li>
      </ul>
  </ul>
  <b>Results</b>
  <p class="tech">
    The CLIP-Conditioned approach achieved higher-quality Monet-style generations than the baseline while requiring only 1/3 of the training time. Longer training could further improve results.
  </p>
  <img src="bleh.png" alt="Resulting Image Generations" width="500" height="350" style="display: block; margin: 0 auto;">

</section>
<hr>

<h3>Links</h3>
<ul>
  <li><a href="https://github.com/chohbein">GitHub</a></li>
  <li id="email-header" style="cursor:pointer; color:blue; text-decoration:underline;">Email</li>
</ul>

<script>
  const email = "chohbein2@gmail.com";
  document.getElementById("email-header").addEventListener("click", () => {
    navigator.clipboard.writeText(email).then(() => {
      alert("Email copied to clipboard!");
    });
  });
</script>
</body>
</html>
